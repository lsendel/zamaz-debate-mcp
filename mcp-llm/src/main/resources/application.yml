spring:
  application:
    name: mcp-llm
  
  # Redis configuration imported from common module
  config:
    import:
      - "classpath:application-redis.yml"
  
  profiles:
    include:
      - redis-medium-throughput

server:
  port: ${SERVER_PORT:5002}
  servlet:
    context-path: /

management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics,prometheus
  endpoint:
    health:
      show-details: always
    metrics:
      enabled: true
    prometheus:
      enabled: true

logging:
  level:
    root: ${LOG_LEVEL:INFO}
    com.zamaz.mcp: ${LOG_LEVEL:INFO}
    org.springframework.web: INFO
    org.springframework.data.redis: INFO

mcp:
  cache:
    enabled: true
    default-ttl: PT30M
    redis:
      enabled: true
      max-memory-policy: allkeys-lru
      key-prefixes:
        llm: llm:
        context: ctx:
        debate: dbt:
        rag: rag:
        template: tpl:
  
  llm:
    cache:
      enabled: true
      ttl: PT24H
      model-ttl:
        claude: PT24H
        gpt: PT12H
        gemini: PT24H
        llama: PT48H
    
    providers:
      claude:
        enabled: ${CLAUDE_ENABLED:true}
        api-key: ${CLAUDE_API_KEY:}
        base-url: ${CLAUDE_BASE_URL:https://api.anthropic.com}
        models:
          - name: claude-3-opus-20240229
            max-tokens: 100000
          - name: claude-3-sonnet-20240229
            max-tokens: 100000
          - name: claude-3-haiku-20240307
            max-tokens: 200000
      
      openai:
        enabled: ${OPENAI_ENABLED:true}
        api-key: ${OPENAI_API_KEY:}
        base-url: ${OPENAI_BASE_URL:https://api.openai.com}
        models:
          - name: gpt-4
            max-tokens: 8192
          - name: gpt-4-turbo
            max-tokens: 128000
          - name: gpt-3.5-turbo
            max-tokens: 16385
      
      gemini:
        enabled: ${GEMINI_ENABLED:true}
        api-key: ${GEMINI_API_KEY:}
        base-url: ${GEMINI_BASE_URL:https://generativelanguage.googleapis.com}
        models:
          - name: gemini-pro
            max-tokens: 32768
          - name: gemini-ultra
            max-tokens: 32768
      
      ollama:
        enabled: ${OLLAMA_ENABLED:false}
        base-url: ${OLLAMA_BASE_URL:http://ollama:11434}
        models:
          - name: llama2:70b
            max-tokens: 4096
          - name: mistral:7b
            max-tokens: 8192
