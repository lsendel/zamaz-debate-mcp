apiVersion: apps/v1
kind: Deployment
metadata:
  name: cluster-autoscaler
  namespace: kube-system
  labels:
    app: cluster-autoscaler
    component: autoscaling
spec:
  replicas: 1
  selector:
    matchLabels:
      app: cluster-autoscaler
  template:
    metadata:
      labels:
        app: cluster-autoscaler
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8085"
        prometheus.io/path: "/metrics"
        cluster-autoscaler.kubernetes.io/safe-to-evict: "false"
    spec:
      priorityClassName: system-cluster-critical
      securityContext:
        runAsNonRoot: true
        runAsUser: 65534
        fsGroup: 65534
      serviceAccountName: cluster-autoscaler
      containers:
      - image: registry.k8s.io/autoscaling/cluster-autoscaler:v1.28.2
        name: cluster-autoscaler
        resources:
          limits:
            cpu: 100m
            memory: 600Mi
          requests:
            cpu: 100m
            memory: 600Mi
        command:
        - ./cluster-autoscaler
        - --v=2
        - --stderrthreshold=info
        - --cloud-provider=aws
        - --skip-nodes-with-local-storage=false
        - --expander=least-waste
        - --node-group-auto-discovery=asg:tag=k8s.io/cluster-autoscaler/enabled,k8s.io/cluster-autoscaler/mcp-production
        - --balance-similar-node-groups
        - --scale-down-enabled=true
        - --scale-down-delay-after-add=10m
        - --scale-down-unneeded-time=10m
        - --scale-down-delay-after-delete=10s
        - --scale-down-delay-after-failure=3m
        - --scale-down-utilization-threshold=0.5
        - --skip-nodes-with-system-pods=false
        - --max-node-provision-time=15m
        - --scan-interval=10s
        - --max-nodes-total=100
        - --cores-total=0:1000
        - --memory-total=0:1000
        - --gpu-total=0:16
        - --new-pod-scale-up-delay=0s
        - --max-empty-bulk-delete=10
        - --max-graceful-termination-sec=600
        - --ignore-daemonsets-utilization=false
        - --ignore-mirror-pods-utilization=false
        - --write-status-configmap=true
        - --status-config-map-name=cluster-autoscaler-status
        - --leader-elect=true
        - --leader-elect-lease-duration=15s
        - --leader-elect-renew-deadline=10s
        - --leader-elect-retry-period=2s
        - --leader-elect-resource-lock=leases
        - --leader-elect-resource-name=cluster-autoscaler
        - --leader-elect-resource-namespace=kube-system
        - --emit-per-nodegroup-metrics=true
        - --feature-gates=BalanceSimilarNodeGroups=true
        env:
        - name: AWS_REGION
          value: us-east-1
        - name: AWS_STS_REGIONAL_ENDPOINTS
          value: regional
        volumeMounts:
        - name: ssl-certs
          mountPath: /etc/ssl/certs/ca-certificates.crt
          readOnly: true
        imagePullPolicy: Always
        ports:
        - containerPort: 8085
          name: metrics
          protocol: TCP
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: /health-check
            port: 8085
            scheme: HTTP
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 10
        readinessProbe:
          failureThreshold: 3
          httpGet:
            path: /health-check
            port: 8085
            scheme: HTTP
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 10
      volumes:
      - name: ssl-certs
        hostPath:
          path: /etc/ssl/certs/ca-certificates.crt
          type: File
      nodeSelector:
        kubernetes.io/os: linux
        kubernetes.io/arch: amd64
        node-role.kubernetes.io/control-plane: ""
      tolerations:
      - effect: NoSchedule
        key: node-role.kubernetes.io/control-plane
      - effect: NoSchedule
        key: node-role.kubernetes.io/master
---
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    k8s-addon: cluster-autoscaler.addons.k8s.io
    k8s-app: cluster-autoscaler
  name: cluster-autoscaler
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: cluster-autoscaler
  labels:
    k8s-addon: cluster-autoscaler.addons.k8s.io
    k8s-app: cluster-autoscaler
rules:
- apiGroups: [""]
  resources: ["events", "endpoints"]
  verbs: ["create", "patch"]
- apiGroups: [""]
  resources: ["pods/eviction"]
  verbs: ["create"]
- apiGroups: [""]
  resources: ["pods/status"]
  verbs: ["update"]
- apiGroups: [""]
  resources: ["endpoints"]
  resourceNames: ["cluster-autoscaler"]
  verbs: ["get", "update"]
- apiGroups: [""]
  resources: ["nodes"]
  verbs: ["watch", "list", "get", "update"]
- apiGroups: [""]
  resources: ["namespaces", "pods", "services", "replicationcontrollers", "persistentvolumeclaims", "persistentvolumes"]
  verbs: ["watch", "list", "get"]
- apiGroups: ["extensions"]
  resources: ["replicasets", "daemonsets"]
  verbs: ["watch", "list", "get"]
- apiGroups: ["policy"]
  resources: ["poddisruptionbudgets"]
  verbs: ["watch", "list"]
- apiGroups: ["apps"]
  resources: ["statefulsets", "replicasets", "daemonsets"]
  verbs: ["watch", "list", "get"]
- apiGroups: ["storage.k8s.io"]
  resources: ["storageclasses", "csinodes", "csidrivers", "csistoragecapacities"]
  verbs: ["watch", "list", "get"]
- apiGroups: ["batch", "extensions"]
  resources: ["jobs"]
  verbs: ["get", "list", "watch", "patch"]
- apiGroups: ["coordination.k8s.io"]
  resources: ["leases"]
  verbs: ["create"]
- apiGroups: ["coordination.k8s.io"]
  resourceNames: ["cluster-autoscaler"]
  resources: ["leases"]
  verbs: ["get", "update"]
- apiGroups: [""]
  resources: ["configmaps"]
  verbs: ["create", "list", "watch"]
- apiGroups: [""]
  resources: ["configmaps"]
  resourceNames: ["cluster-autoscaler-status", "cluster-autoscaler-priority-expander"]
  verbs: ["delete", "get", "update", "watch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: cluster-autoscaler
  labels:
    k8s-addon: cluster-autoscaler.addons.k8s.io
    k8s-app: cluster-autoscaler
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-autoscaler
subjects:
- kind: ServiceAccount
  name: cluster-autoscaler
  namespace: kube-system
---
# Priority class for cluster autoscaler
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: system-cluster-critical
value: 2000000000
globalDefault: false
description: "Used for system critical pods that must run in the cluster, but can be moved to another node if necessary."
---
# Service for cluster autoscaler metrics
apiVersion: v1
kind: Service
metadata:
  name: cluster-autoscaler
  namespace: kube-system
  labels:
    app: cluster-autoscaler
spec:
  selector:
    app: cluster-autoscaler
  ports:
  - name: metrics
    port: 8085
    targetPort: 8085
    protocol: TCP
---
# ServiceMonitor for Prometheus
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: cluster-autoscaler
  namespace: kube-system
  labels:
    app: cluster-autoscaler
spec:
  selector:
    matchLabels:
      app: cluster-autoscaler
  endpoints:
  - port: metrics
    interval: 30s
    path: /metrics
    honorLabels: true
---
# ConfigMap for autoscaler configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: cluster-autoscaler-config
  namespace: kube-system
  labels:
    app: cluster-autoscaler
data:
  # Node groups configuration for AWS Auto Scaling Groups
  nodegroups.yaml: |
    nodeGroups:
      # General purpose nodes
      - name: "mcp-general-nodes"
        minSize: 3
        maxSize: 20
        desiredCapacity: 5
        instanceType: "m5.large"
        diskSize: 100
        labels:
          node-type: "general"
          workload: "standard"
        taints: []
        
      # Compute-intensive nodes for LLM workloads
      - name: "mcp-compute-nodes"
        minSize: 1
        maxSize: 10
        desiredCapacity: 2
        instanceType: "c5.2xlarge"
        diskSize: 200
        labels:
          node-type: "compute"
          workload: "llm"
        taints:
        - key: "workload"
          value: "llm"
          effect: "NoSchedule"
          
      # Memory-intensive nodes for context processing
      - name: "mcp-memory-nodes"
        minSize: 1
        maxSize: 8
        desiredCapacity: 2
        instanceType: "r5.xlarge"
        diskSize: 150
        labels:
          node-type: "memory"
          workload: "context"
        taints:
        - key: "workload"
          value: "context"
          effect: "NoSchedule"
          
      # Spot instances for cost optimization
      - name: "mcp-spot-nodes"
        minSize: 0
        maxSize: 15
        desiredCapacity: 3
        instanceType: "m5.large"
        diskSize: 100
        spotPrice: "0.05"
        labels:
          node-type: "spot"
          workload: "batch"
        taints:
        - key: "spot-instance"
          value: "true"
          effect: "NoSchedule"
          
  # Priority expander configuration
  priority-expander.yaml: |
    priorities:
      100: "mcp-spot-nodes"     # Prefer spot instances for cost savings
      90:  "mcp-general-nodes"  # Then general purpose nodes
      80:  "mcp-memory-nodes"   # Then memory-optimized nodes
      70:  "mcp-compute-nodes"  # Finally compute-optimized nodes
      
  # Scaling policies
  scaling-policies.yaml: |
    scaleUpPolicies:
      # Aggressive scale-up during business hours
      - schedule: "0 8-18 * * 1-5"  # Mon-Fri 8AM-6PM
        minNodes: 5
        maxNodes: 50
        scaleUpCooldown: "2m"
        
      # Conservative scale-up during off-hours
      - schedule: "0 19-7 * * *"    # Evenings and nights
        minNodes: 3
        maxNodes: 20
        scaleUpCooldown: "5m"
        
      # Weekend scaling
      - schedule: "0 * * * 0,6"     # Weekends
        minNodes: 2
        maxNodes: 15
        scaleUpCooldown: "10m"
        
    scaleDownPolicies:
      # Business hours - slower scale down
      - schedule: "0 8-18 * * 1-5"
        scaleDownDelay: "15m"
        scaleDownUnneededTime: "15m"
        
      # Off-hours - faster scale down
      - schedule: "0 19-7 * * *"
        scaleDownDelay: "5m"
        scaleDownUnneededTime: "5m"
---
# PodDisruptionBudget for cluster autoscaler
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: cluster-autoscaler-pdb
  namespace: kube-system
spec:
  minAvailable: 1
  selector:
    matchLabels:
      app: cluster-autoscaler